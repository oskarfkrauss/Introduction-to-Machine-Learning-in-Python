{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0ecd2a",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "This week we will be looking at a subfield of unsupervised learning - clustering. This goal is to first have a go at implementing the classic k-means clustering algorithm in python using only numpy, then like previous weeks, you can compare your result to scitkit-learn.\n",
    "\n",
    "The second (optional) task is to try and use some off-the-shelf clustering algorithms provided by scikit-learn to help cluster some more complicated datasets. All the clustering algorithms implemented by scikit-learn can be found here (https://scikit-learn.org/stable/modules/clustering.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1974bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons, make_circles, make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Simulated dataset) DO NOT CHANGE THIS CODE\n",
    "n_samples = 300\n",
    "n_features = 2  \n",
    "n_clusters = 3 \n",
    "random_state = 42  # For reproducibility\n",
    "\n",
    "# Create the data\n",
    "X, y_true = make_blobs(n_samples=n_samples, centers=n_clusters, n_features=n_features, random_state=random_state)\n",
    "\n",
    "# Plot the generated data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50, c='gray', marker='o', alpha=0.6)\n",
    "plt.title(\"Synthetic Data (Unlabeled)\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dd2644",
   "metadata": {},
   "source": [
    "### Now it's your turn\n",
    "\n",
    "Try and have a go at implementing k means clustering using the boiler plate code below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775ab47",
   "metadata": {},
   "source": [
    "### Some helper functions\n",
    "\n",
    "First I've provided you with some helper functions provided by numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9782548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the euclidean norm\n",
    "a = np.array([1., 0.2, 4.5, -0.6])\n",
    "print(np.linalg.norm(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the minimum index\n",
    "a = np.array([1., 0.2, 4.5, -0.6])\n",
    "# output should be 3 since the smallest values -0.6 is in position 3 in the array a\n",
    "print(np.argmin(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4844ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualtes the mean\n",
    "a = np.mean([1., 0.2, 4.5, -0.6])\n",
    "print(np.mean(a))\n",
    "print(a.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb71c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you are debugging remember it is always helpful to print out the shape of the array you are dealining with\n",
    "# this will help you understand which axis to apply operations and if the operations are being applied as intended\n",
    "a = np.array([1., 0.2, 4.5, -0.6])\n",
    "b = np.array([[1., 0.9], [0.2, -0.1], [4.5, 2.0], [-0.6, 9.0]])\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591dc7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b50538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_clustering(X, k, max_iters=100, tolerance=1e-4):\n",
    "    \"\"\"\n",
    "    A simple implementation of K-Means Clustering.\n",
    "    \n",
    "    Parameters:\n",
    "        X (array): Input data.\n",
    "        k (int): Number of clusters.\n",
    "        max_iters (int): Maximum iterations for the algorithm.\n",
    "        tolerance (float): Convergence tolerance.\n",
    "    \n",
    "    Returns:\n",
    "        centroids (array): Final cluster centroids.\n",
    "        labels (array): Assigned cluster labels for each point.\n",
    "    \"\"\"\n",
    "    # DO NOT CHANGE THE RANDOM SEED\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # TODO 1: how are you going to randoly initialize your clusters?\n",
    "    indices = np.random.choice(X.shape[0],size=k, replace=False)\n",
    "    centroids = X[indices]\n",
    "    \n",
    "    print(np.min(X, axis=0))\n",
    "    \n",
    "    centroids = np.random.uniform(low=np.min(X, axis=0), high=np.max(X, axis=0), size=(k, X.shape[1]))\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        \n",
    "        # TODO 2: first step of the algorithm assigning points to the nearest centroid\n",
    "        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        \n",
    "        # TODO 3: second step of the algorithm compute the new means given the new cluster assignment\n",
    "        new_centroids = np.array([np.mean(X[labels == cluster], axis=0) for cluster in range(k)])\n",
    "        \n",
    "        # LEAVE THIS LINE OF CODE - CHECKS FOR EARLY CONVERGENCE\n",
    "        if np.all(np.abs(new_centroids - centroids) < tolerance):\n",
    "            break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return centroids, labels\n",
    "\n",
    "# TODO 4: apply your k-means clustering function\n",
    "k = 3  # Number of clusters\n",
    "centroids, labels = k_means_clustering(X, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeff577",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for cluster in range(k):\n",
    "    cluster_points = X[labels == cluster]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], s=50, label=f'Cluster {cluster}')\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=200, label='Centroids')\n",
    "plt.title(\"K-Means Clustering Results\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8907ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 3  # Number of clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(X)\n",
    "sklearn_labels = kmeans.labels_\n",
    "sklearn_centroids = kmeans.cluster_centers_\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cluster in range(k):\n",
    "    cluster_points = X[sklearn_labels == cluster]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], s=50, label=f'Cluster {cluster}')\n",
    "plt.scatter(sklearn_centroids[:, 0], sklearn_centroids[:, 1], c='red', marker='X', s=200, label='Centroids')\n",
    "plt.title(\"K-Means Clustering Results (sklearn)\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69f2ab",
   "metadata": {},
   "source": [
    "### More complicated datasets\n",
    "\n",
    "Below I have generated some more complicated datasets that k-means will struggle on, have a go at trying to cluster one of these datasets using some of the off-the-shelf clustering algorithms provided by scikit-learn (https://scikit-learn.org/stable/modules/clustering.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83219ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Generating datasets) DO NOT CHANGE THIS CODE\n",
    "datasets = {\n",
    "    \"Moons\": make_moons(n_samples=300, noise=0.05, random_state=42),\n",
    "    \"Circles\": make_circles(n_samples=300, noise=0.05, factor=0.5, random_state=42),\n",
    "    \"Unequal Blobs\": make_blobs(n_samples=300, centers=3, cluster_std=[1.0, 2.5, 0.5], random_state=42),\n",
    "    \"Anisotropic Gaussian\": make_blobs(n_samples=300, centers=3, random_state=42)[0],\n",
    "}\n",
    "\n",
    "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "datasets[\"Anisotropic Gaussian\"] = np.dot(datasets[\"Anisotropic Gaussian\"], transformation)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i, (name, data) in enumerate(datasets.items(), 1):\n",
    "    X, _ = data if isinstance(data, tuple) else (data, None)\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=30, c='gray', alpha=0.7)\n",
    "    plt.title(name)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af11b2dd",
   "metadata": {},
   "source": [
    "### Now it's your turn\n",
    "\n",
    "Now it is your go to try and cluster one of these datasets. This is more an exercise in learning how to read through library documentation to find the best method available to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9355de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1: import your clustering algorithm from scikit-learn\n",
    "\n",
    "# TODO 2: choose a data set, change \"Circles\" to the desired dataset\n",
    "X, _ = datasets[\"Circles\"]\n",
    "\n",
    "# TODO 3: choose the number of clusters\n",
    "n_clusters = 2\n",
    "\n",
    "# TODO 4: instantiate a clustering algorithm from scikit-learn\n",
    "\n",
    "# TODO 5: get the labels of each data point for the corresponding clustering\n",
    "labels = ?\n",
    "\n",
    "# (Plot results) DO NOT CHANGE THIS CODE\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_circles[:, 0], X_circles[:, 1], c=labels, cmap='viridis', s=30)\n",
    "plt.title(\"Spectral Clustering on Circles Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb645e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
